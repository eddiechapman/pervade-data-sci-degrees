---
title: "Course Cleaning"
output: html_notebook
---

```{r include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  warning = FALSE,
  message = FALSE,
  error = FALSE, 
  cache = FALSE
)
```

```{r}
library(dplyr)
library(ggplot2)

theme_set(theme_classic())


courses_df <- readr::read_csv(
  file.path('data-raw', 'courses.csv'), 
  show_col_types = FALSE
)
```

Splitting on new lines

```{r}
nrow(courses_df) 
```

Removing blank lines drops the total in half.

```{r}
courses_df <-
  courses_df %>%
  filter(!is.na(course))
```

```{r}
nrow(courses_df)
```

Looking at extra long course text:

```{r}
courses_df %>%
  filter(str_length(course) > 80)
```

It seems like most of these are course descriptions. There are some valid courses in there but out of 1,653 rows I'd estimate less than 5% are useful. It think it is OK to drop them.

```{r}
courses_df <-
  courses_df %>%
  filter(str_length(course) < 80)

nrow(courses_df)
```

Down to 16,000.

```{r}
courses_df %>%
  slice_sample(n = 20)
```

I want to remove any parentheses or brackets and whatever is in them.

```{r}
pattern <- regex('[\\(\\[].*[\\)\\]]')

courses_df <-
  courses_df %>%
  mutate(course = str_remove(course, pattern))

courses_df %>%
  slice_sample(n = 60)
```
Let's chop out the shortest course names.

```{r}
courses_df %>%
  filter(str_length(course) < 10) %>%
  arrange(str_length(course))
```

I saw nothing under length 7 that was worth saving.

```{r}
courses_df <-
  courses_df %>%
  filter(str_length(course) >= 7)

nrow(courses_df)
```


```{r}
slice_sample(courses_df, n = 60) %>% select(course)
```

I want to get rid of the course code and department abbreviation at the begining
of course text. 

Here is courses with mixed letters and numbers at the beginning:

```{r}
pattern <- regex('^\\w*\\d[\\w\\d[:punct:]]+[[:space:]]?[[:punct:]]?[[:space:]]?')

courses_df %>% 
  mutate(extracted = str_extract(course, pattern)) %>%
  filter(!is.na(extracted)) %>%
  select(extracted)

```

```{r}
courses_df <-
  courses_df %>%
  mutate(course = str_remove(course, pattern))
```

```{r}
courses_df %>% slice_sample(n = 50)
```

```{r}
pattern <- regex('^[:alpha:]{2,5}[:blank:]?[:digit:]{3,4}', ignore_case = TRUE)

courses_df %>% 
  mutate(extracted = str_extract(course, pattern)) %>%
  filter(!is.na(extracted)) %>%
  select(extracted)
```

```{r}
courses_df <- 
  courses_df %>%
  mutate(course = str_remove(course, pattern))
```

```{r}
slice_sample(courses_df, n = 60) %>% select(course)
```

Looking good! Let's get rid of any punctuation characters at the start of 
courses.

First I'm going to trim any leading blank spaces, then trim the punctuation,
then trim any remaining whitespace.

OK, now to remove the leading punctuation.

```{r}
pattern <- regex('^[[:punct:]]')

courses_df <-
  courses_df %>%
  mutate(course = str_trim(course, side = 'left'),
         course = str_remove(course, pattern),
         course = str_trim(course, side = 'left'))
```

```{r}
courses_df %>% 
  slice_sample(n = 50) %>% 
  select(course)
```
Looking pretty good!

Bet we have a bunch of short stubs if we sort by length.

```{r}
courses_df %>%
  filter(str_length(course) < 7) %>%
  select(course) %>%
  arrange(str_length(course)) 
```

Yeah, it's a bunch of blanks.

Let's remove them and see what we have left.

```{r}
courses_df <-
  courses_df %>%
  filter(str_length(course) >= 7)

nrow(courses_df)
```

```{r}
slice_sample(courses_df, n = 100) %>% select(course)
```

Let's try removing some stop words.

I'm thinking:
- required
- elective
- course
- courses
- credits
- credit
- choose
- following
- summer
- fall
- winter
- spring

Some of these indicate a phrase which is not a course at all, like "Required courses".

Say the course text was "Required Statistics Courses". If we pull out "required" and
"courses", we're left with "statistics" which sounds like the name of a course. But it's not.

In that case, we just want to delete the whole course text if we find "required". 

This includes:
- course
- courses
- required
- requirements
- elective
- choose
- following

For other words, we just want to remove the word but leave the rest of the text. 

Example: "Data Mining 3 Credits". We want to remove "Credits" (and later, "3") but 
we should keep "Data Mining". 

These words are:
- credits
- credit
- cr
- hour
- hr
- hours

I'm not sure what to do with fall/winter/spring/summer yet. 

Starting by deleting full course text:

```{r}
pattern <- regex('course|courses|required|requirements|elective|choose|following', ignore_case = T)

courses_df %>%
  filter(str_detect(course, pattern))
```

This looks great. Let's get rid of 'em.

```{r}
courses_df <- 
  courses_df %>%
  filter(!str_detect(course, pattern))

nrow(courses_df)
```

Getting down there!

How's it look?

```{r}
slice_sample(courses_df, n = 100) %>% select(course)
```

Now let's remove those other words but not delete the whole course text.

```{r}
pattern <- regex('credits|credit|hour|hours|semester|units', ignore_case = T)

courses_df %>%
  mutate(course = str_remove_all(course, pattern)) 
```

That looks good. Let's do it.

```{r}
courses_df <-
  courses_df %>%
  mutate(course = str_remove_all(course, pattern)) 

nrow(courses_df)
```

Removing any sub-7 length courses:

```{r}
courses_df <-
  courses_df %>%
  filter(str_length(course) >= 7)

nrow(courses_df)
```

Okie doke! Let's take a random slice and see how it's looking:

```{r}
slice_sample(courses_df, n = 100) %>% select(course)
```

Pretty clean! One of the last things to do is get rid of numbers.

I'm going to come back to that one. 

Saving for now:

```{r}
readr::write_csv(courses_df, file = file.path('data', 'courses.csv'))
```

